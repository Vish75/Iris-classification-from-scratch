{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f8e2073c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "fa8f1e90",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('mt.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "08d1e570",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>F1</th>\n",
       "      <th>F2</th>\n",
       "      <th>T1</th>\n",
       "      <th>T2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>5.2</td>\n",
       "      <td>2.3</td>\n",
       "      <td>2</td>\n",
       "      <td>11.96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>5.0</td>\n",
       "      <td>1.9</td>\n",
       "      <td>2</td>\n",
       "      <td>9.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>5.2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2</td>\n",
       "      <td>10.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>5.4</td>\n",
       "      <td>2.3</td>\n",
       "      <td>2</td>\n",
       "      <td>12.42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>5.1</td>\n",
       "      <td>1.8</td>\n",
       "      <td>2</td>\n",
       "      <td>9.18</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>150 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      F1   F2  T1     T2\n",
       "0    1.4  0.2   1   0.28\n",
       "1    1.4  0.2   1   0.28\n",
       "2    1.3  0.2   1   0.26\n",
       "3    1.5  0.2   1   0.30\n",
       "4    1.4  0.2   1   0.28\n",
       "..   ...  ...  ..    ...\n",
       "145  5.2  2.3   2  11.96\n",
       "146  5.0  1.9   2   9.50\n",
       "147  5.2  2.0   2  10.40\n",
       "148  5.4  2.3   2  12.42\n",
       "149  5.1  1.8   2   9.18\n",
       "\n",
       "[150 rows x 4 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "30362979",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.iloc[:,:2]\n",
    "class_target = df['T1']\n",
    "reg_target = df['T2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "6eb6e42b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python39\\lib\\site-packages\\numpy\\core\\fromnumeric.py:84: FutureWarning: In a future version, DataFrame.max(axis=None) will return a scalar max over the entire DataFrame. To retain the old behavior, use 'frame.max(axis=0)' or just 'frame.max()'\n",
      "  return reduction(axis=axis, out=out, **passkwargs)\n"
     ]
    }
   ],
   "source": [
    "X = X/np.max(X)\n",
    "reg_target = reg_target/np.max(reg_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "af77e712",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.        , 0.01764335],\n",
       "       [1.        , 0.01764335],\n",
       "       [1.        , 0.01638311],\n",
       "       [1.        , 0.01890359],\n",
       "       [1.        , 0.01764335],\n",
       "       [1.        , 0.04284814],\n",
       "       [1.        , 0.02646503],\n",
       "       [1.        , 0.01890359],\n",
       "       [1.        , 0.01764335],\n",
       "       [1.        , 0.0094518 ],\n",
       "       [1.        , 0.01890359],\n",
       "       [1.        , 0.02016383],\n",
       "       [1.        , 0.00882168],\n",
       "       [1.        , 0.00693132],\n",
       "       [1.        , 0.01512287],\n",
       "       [1.        , 0.03780718],\n",
       "       [1.        , 0.03276623],\n",
       "       [1.        , 0.02646503],\n",
       "       [1.        , 0.03213611],\n",
       "       [1.        , 0.02835539],\n",
       "       [1.        , 0.02142407],\n",
       "       [1.        , 0.03780718],\n",
       "       [1.        , 0.01260239],\n",
       "       [1.        , 0.05356018],\n",
       "       [1.        , 0.02394455],\n",
       "       [1.        , 0.02016383],\n",
       "       [1.        , 0.04032766],\n",
       "       [1.        , 0.01890359],\n",
       "       [1.        , 0.01764335],\n",
       "       [1.        , 0.02016383],\n",
       "       [1.        , 0.02016383],\n",
       "       [1.        , 0.03780718],\n",
       "       [1.        , 0.0094518 ],\n",
       "       [1.        , 0.01764335],\n",
       "       [1.        , 0.0094518 ],\n",
       "       [1.        , 0.01512287],\n",
       "       [1.        , 0.01638311],\n",
       "       [1.        , 0.0094518 ],\n",
       "       [1.        , 0.01638311],\n",
       "       [1.        , 0.01890359],\n",
       "       [1.        , 0.02457467],\n",
       "       [1.        , 0.02457467],\n",
       "       [1.        , 0.01638311],\n",
       "       [1.        , 0.06049149],\n",
       "       [1.        , 0.0478891 ],\n",
       "       [1.        , 0.02646503],\n",
       "       [1.        , 0.02016383],\n",
       "       [1.        , 0.01764335],\n",
       "       [1.        , 0.01890359],\n",
       "       [1.        , 0.01764335],\n",
       "       [2.        , 0.41461878],\n",
       "       [2.        , 0.42533081],\n",
       "       [2.        , 0.463138  ],\n",
       "       [2.        , 0.32766226],\n",
       "       [2.        , 0.43478261],\n",
       "       [2.        , 0.36862004],\n",
       "       [2.        , 0.47385003],\n",
       "       [2.        , 0.20793951],\n",
       "       [2.        , 0.37681159],\n",
       "       [2.        , 0.34404537],\n",
       "       [2.        , 0.2205419 ],\n",
       "       [2.        , 0.39697543],\n",
       "       [2.        , 0.25204789],\n",
       "       [2.        , 0.41461878],\n",
       "       [2.        , 0.29489603],\n",
       "       [2.        , 0.38815375],\n",
       "       [2.        , 0.42533081],\n",
       "       [2.        , 0.25834909],\n",
       "       [2.        , 0.42533081],\n",
       "       [2.        , 0.27032136],\n",
       "       [2.        , 0.54442344],\n",
       "       [2.        , 0.32766226],\n",
       "       [2.        , 0.463138  ],\n",
       "       [2.        , 0.35538752],\n",
       "       [2.        , 0.35223693],\n",
       "       [2.        , 0.38815375],\n",
       "       [2.        , 0.42344045],\n",
       "       [2.        , 0.53560176],\n",
       "       [2.        , 0.42533081],\n",
       "       [2.        , 0.2205419 ],\n",
       "       [2.        , 0.26339004],\n",
       "       [2.        , 0.2331443 ],\n",
       "       [2.        , 0.29489603],\n",
       "       [2.        , 0.51417769],\n",
       "       [2.        , 0.42533081],\n",
       "       [2.        , 0.4536862 ],\n",
       "       [2.        , 0.4442344 ],\n",
       "       [2.        , 0.36042848],\n",
       "       [2.        , 0.33585381],\n",
       "       [2.        , 0.32766226],\n",
       "       [2.        , 0.33270321],\n",
       "       [2.        , 0.4057971 ],\n",
       "       [2.        , 0.30245747],\n",
       "       [2.        , 0.20793951],\n",
       "       [2.        , 0.34404537],\n",
       "       [2.        , 0.31758034],\n",
       "       [2.        , 0.34404537],\n",
       "       [2.        , 0.35223693],\n",
       "       [2.        , 0.20793951],\n",
       "       [2.        , 0.33585381],\n",
       "       [2.        , 0.94517958],\n",
       "       [2.        , 0.61058601],\n",
       "       [2.        , 0.78071834],\n",
       "       [2.        , 0.63516068],\n",
       "       [2.        , 0.80403277],\n",
       "       [2.        , 0.87334594],\n",
       "       [2.        , 0.48204159],\n",
       "       [2.        , 0.71455577],\n",
       "       [2.        , 0.65784499],\n",
       "       [2.        , 0.96093258],\n",
       "       [2.        , 0.64272212],\n",
       "       [2.        , 0.63453056],\n",
       "       [2.        , 0.72778828],\n",
       "       [2.        , 0.63011972],\n",
       "       [2.        , 0.77126654],\n",
       "       [2.        , 0.76811594],\n",
       "       [2.        , 0.62381853],\n",
       "       [2.        , 0.92879647],\n",
       "       [2.        , 1.        ],\n",
       "       [2.        , 0.47258979],\n",
       "       [2.        , 0.82608696],\n",
       "       [2.        , 0.61751733],\n",
       "       [2.        , 0.84436043],\n",
       "       [2.        , 0.5557656 ],\n",
       "       [2.        , 0.75425331],\n",
       "       [2.        , 0.6805293 ],\n",
       "       [2.        , 0.54442344],\n",
       "       [2.        , 0.5557656 ],\n",
       "       [2.        , 0.74102079],\n",
       "       [2.        , 0.5847511 ],\n",
       "       [2.        , 0.73030876],\n",
       "       [2.        , 0.80655325],\n",
       "       [2.        , 0.7763075 ],\n",
       "       [2.        , 0.48204159],\n",
       "       [2.        , 0.49401386],\n",
       "       [2.        , 0.88405797],\n",
       "       [2.        , 0.84688091],\n",
       "       [2.        , 0.62381853],\n",
       "       [2.        , 0.54442344],\n",
       "       [2.        , 0.71455577],\n",
       "       [2.        , 0.84688091],\n",
       "       [2.        , 0.73913043],\n",
       "       [2.        , 0.61058601],\n",
       "       [2.        , 0.85507246],\n",
       "       [2.        , 0.8979206 ],\n",
       "       [2.        , 0.75362319],\n",
       "       [2.        , 0.59861374],\n",
       "       [2.        , 0.65532451],\n",
       "       [2.        , 0.7826087 ],\n",
       "       [2.        , 0.57844991]])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = np.c_[class_target,reg_target]\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "0ed98b89",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.2,random_state=22)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "e1ab537e",
   "metadata": {},
   "outputs": [],
   "source": [
    "classification_target = y_train[:,0]\n",
    "regression_target = y_train[:,1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "22e5b818",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.        , 0.01890359],\n",
       "       [2.        , 0.76811594],\n",
       "       [2.        , 0.43478261],\n",
       "       [2.        , 0.59861374],\n",
       "       [2.        , 0.41461878],\n",
       "       [2.        , 0.42344045],\n",
       "       [2.        , 0.4442344 ],\n",
       "       [2.        , 0.54442344],\n",
       "       [2.        , 0.29489603],\n",
       "       [1.        , 0.01512287],\n",
       "       [2.        , 0.82608696],\n",
       "       [2.        , 0.31758034],\n",
       "       [2.        , 0.73030876],\n",
       "       [2.        , 0.96093258],\n",
       "       [1.        , 0.06049149],\n",
       "       [2.        , 0.80655325],\n",
       "       [2.        , 0.27032136],\n",
       "       [2.        , 0.33585381],\n",
       "       [2.        , 0.47258979],\n",
       "       [2.        , 0.34404537],\n",
       "       [1.        , 0.02016383],\n",
       "       [2.        , 0.73913043],\n",
       "       [1.        , 0.01638311],\n",
       "       [2.        , 0.30245747],\n",
       "       [2.        , 0.61058601],\n",
       "       [1.        , 0.01638311],\n",
       "       [2.        , 0.5847511 ],\n",
       "       [2.        , 0.65532451],\n",
       "       [2.        , 0.75425331],\n",
       "       [2.        , 0.54442344]])"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "8a52a745",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dense_Layer:\n",
    "    def __init__(self, n_inputs, n_neurons):\n",
    "        self.weights = 0.10*np.random.randn(n_inputs, n_neurons)\n",
    "        self.biases = np.zeros((1,n_neurons))\n",
    "    def forward(self,inputs):\n",
    "        self.output = np.dot(inputs,self.weights) + self.biases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "f7b1dbcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Activaition_sigmoid:\n",
    "    def forward(self,inputs):\n",
    "        self.output = 1/(1+np.exp(-inputs))\n",
    "class Activation_tanh:\n",
    "    def forward(self,inputs):\n",
    "        self.output = (np.exp(inputs)- np.exp(-inputs)) / (np.exp(inputs)+ np.exp(-inputs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "57a02c67",
   "metadata": {},
   "outputs": [],
   "source": [
    "layer1 = Dense_Layer(2,3)\n",
    "activation1 = Activaition_sigmoid()\n",
    "layer2 = Dense_Layer(3,3)\n",
    "activation2 = Activation_tanh()\n",
    "layer3 = Dense_Layer(3,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "9e808bb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 cost:  1.592966516156354\n",
      "Epoch 100 cost:  1.594659808760077\n",
      "Epoch 200 cost:  1.5963239671820282\n",
      "Epoch 300 cost:  1.5979596021324125\n",
      "Epoch 400 cost:  1.5995673089593896\n",
      "Epoch 500 cost:  1.6011476682941186\n",
      "Epoch 600 cost:  1.6027012467279271\n",
      "Epoch 700 cost:  1.6042285975077797\n",
      "Epoch 800 cost:  1.6057302612390407\n",
      "Epoch 900 cost:  1.6072067665869683\n",
      "Epoch 1000 cost:  1.6086586309702486\n",
      "Epoch 1100 cost:  1.6100863612416068\n",
      "Final cost:  1.6114765288159634\n"
     ]
    }
   ],
   "source": [
    "for k in range(1200):\n",
    "    # Forward propogation\n",
    "    layer1.forward(X_train)\n",
    "    activation1.forward(layer1.output)\n",
    "    layer2.forward(activation1.output)\n",
    "    activation2.forward(layer2.output)\n",
    "    layer3.forward(activation2.output)\n",
    "    # For softmax\n",
    "    use_val = []\n",
    "    for i in layer3.output:\n",
    "        use_val.append(i[0])\n",
    "    exp_val = np.exp(use_val)\n",
    "    out_val = exp_val / np.sum(exp_val)\n",
    "    # For linear activation for regression:\n",
    "    reg_out = []\n",
    "    for i in layer3.output:\n",
    "        reg_out.append(i[1])\n",
    "    # Log loss:\n",
    "    classification_error = 0\n",
    "    for i in range(120):\n",
    "        if classification_target[i]==1.:\n",
    "            classification_error = classification_error + np.log(out_val[i])\n",
    "        else:\n",
    "            classification_error = classification_error + np.log(1-out_val[i])\n",
    "    classification_error = -1*(classification_error/120)\n",
    "    # MSE:\n",
    "    regression_error = 0\n",
    "    diff = regression_target - reg_out\n",
    "    regression_error = np.dot(diff,diff.T)\n",
    "    regression_error = regression_error/120\n",
    "    # Total error:\n",
    "    weight_classification = classification_error/(classification_error + regression_error)\n",
    "    weight_regression = regression_error/(classification_error + regression_error)\n",
    "    tot_error = weight_classification*classification_error + weight_regression*regression_error\n",
    "    # Backpropogation:\n",
    "    delta = out_val - classification_target\n",
    "    delta_new = reg_out - regression_target\n",
    "    del_tot = np.c_[delta,delta_new]\n",
    "    learning_rate = 0.0001\n",
    "    layer3.weights = layer3.weights + learning_rate* (1/120)*np.dot(activation2.output.T,del_tot)\n",
    "    db2 = (1/120)*np.sum(del_tot, axis=0, keepdims=True)\n",
    "    layer3.biases = layer3.biases + learning_rate * db2\n",
    "    d2 = del_tot.dot(layer3.weights.T)*(1 - np.power(activation2.output, 2))\n",
    "    del2 = np.dot(activation1.output.T,d2)\n",
    "    layer2.weights = layer2.weights + learning_rate*(1/120)*del2\n",
    "    delb2 = np.sum(d2, axis=0)\n",
    "    layer2.biases = layer2.biases + learning_rate*(1/120)*delb2\n",
    "    dL = np.dot((activation1.output*(1-activation1.output)),del2.dot(layer2.weights.T))\n",
    "    d_new = np.dot(X_train.T,dL)\n",
    "    layer1.weights = layer1.weights + learning_rate*(1/120)*d_new\n",
    "    dB3 = np.sum(dL, axis = 0)\n",
    "    layer1.biases = layer1.biases + learning_rate*(1/120)*dB3\n",
    "    if k%100==0:\n",
    "        print(\"Epoch\",k ,\"cost: \",tot_error)\n",
    "print(\"Final cost: \",tot_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "f5536b92",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.03332734, 0.03333833, 0.03333359, 0.03333593, 0.03333283,\n",
       "       0.03333274, 0.03333351, 0.03333544, 0.0333331 , 0.03332759,\n",
       "       0.03333798, 0.03333191, 0.03333496, 0.03333895, 0.03333001,\n",
       "       0.03333537, 0.03333149, 0.03333267, 0.03333325, 0.03333259,\n",
       "       0.03332726, 0.03333851, 0.0333275 , 0.03333208, 0.03333584,\n",
       "       0.0333275 , 0.03333322, 0.03333642, 0.03333665, 0.03333544])"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Testing part:\n",
    "z1 = np.dot(X_test,layer1.weights) + layer1.biases\n",
    "activation1.forward(z1)\n",
    "a1 = activation1.output\n",
    "z2 = np.dot(a1,layer2.weights) + layer2.biases\n",
    "activation2.forward(z2)\n",
    "a2 = activation2.output\n",
    "z3 = np.dot(a2,layer3.weights) + layer3.biases \n",
    "use1_val = []\n",
    "for i in z3:\n",
    "    use1_val.append(i[0])\n",
    "exp1_val = np.exp(use1_val)\n",
    "out1_val = exp1_val / np.sum(exp1_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "fab8ec9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.03332734, 0.03333833, 0.03333359, 0.03333593, 0.03333283,\n",
       "       0.03333274, 0.03333351, 0.03333544, 0.0333331 , 0.03332759,\n",
       "       0.03333798, 0.03333191, 0.03333496, 0.03333895, 0.03333001,\n",
       "       0.03333537, 0.03333149, 0.03333267, 0.03333325, 0.03333259,\n",
       "       0.03332726, 0.03333851, 0.0333275 , 0.03333208, 0.03333584,\n",
       "       0.0333275 , 0.03333322, 0.03333642, 0.03333665, 0.03333544])"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Classification output\n",
    "out1_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "00bf4815",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.03670848, 0.03697037, 0.03686707, 0.03691857, 0.03685275,\n",
       "       0.03685205, 0.03686637, 0.03690645, 0.03684666, 0.03671035,\n",
       "       0.03696741, 0.03682887, 0.03691061, 0.03699123, 0.0367634 ,\n",
       "       0.03692189, 0.03681721, 0.03684324, 0.03686427, 0.03684255,\n",
       "       0.03670785, 0.03697185, 0.03670972, 0.03683024, 0.03691785,\n",
       "       0.03670972, 0.03687219, 0.03693065, 0.0369405 , 0.03690645])"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Regression output\n",
    "z3[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c35df21",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
